{"cells":[{"cell_type":"markdown","metadata":{"id":"vUXNQZtwEYiQ"},"source":["# Running MegaDetector on camera trap images using Google Colab\n","\n","[Open this notebook in Colab](https://colab.research.google.com/github/microsoft/CameraTraps/blob/main/detection/megadetector_colab.ipynb)\n","\n","Adapted from previous versions by [@louis030195](https://github.com/louis030195) \n","and [@alsnothome](https://github.com/alsnothome).\n","\n","Also see the [MegaDetector guide on GitHub](https://github.com/microsoft/CameraTraps/blob/main/megadetector.md).\n","\n","This notebook is designed to load camera trap images that have already been uploaded to Google Drive. If you don't have your own images on Google Drive, this notebook will show you how to download some sample images from [LILA](https://lila.science).\n","\n","MegaDetector output is saved in a .json file whose format is described  [here](https://github.com/microsoft/CameraTraps/tree/main/api/batch_processing#batch-processing-api-output-format). The last cell in this notebook will give you some pointers on how users typically work with MegaDetector output."]},{"cell_type":"markdown","metadata":{"id":"9aUlxnm7cnWy"},"source":["## Set up the Colab instance to run on a GPU accelerator\n","\n","\n","Navigate to Edit→Notebook Settings and select \"GPU\" from the \"Hardware accelerator\" drop-down menu."]},{"cell_type":"markdown","metadata":{"id":"LUyqKSAWRGNw"},"source":["## Install dependencies, download the model, set up your PYTHONPATH\n","\n","From here on, you'll start seeing a mix of code and Linux system commands. System commands are prefixed by a shebang `!`, which tells this notebook to execute them on the command line."]},{"cell_type":"markdown","metadata":{"id":"VtNnMxtte0EF"},"source":["### Install required Python packages\n","\n","This may take 2-3 minutes."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"EMEkgpy6T0pr","executionInfo":{"status":"ok","timestamp":1668204822106,"user_tz":480,"elapsed":6775,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}},"outputId":"66ffa1a9-b10a-4aa7-e04c-1918fa61eb2f","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting humanfriendly\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 5.1 MB/s \n","\u001b[?25hCollecting jsonpickle\n","  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonpickle) (4.13.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonpickle) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonpickle) (3.10.0)\n","Installing collected packages: jsonpickle, humanfriendly\n","Successfully installed humanfriendly-10.0 jsonpickle-2.2.0\n"]}],"source":["pip install humanfriendly jsonpickle"]},{"cell_type":"code","source":["pip install azure-storage-blob>=12.5"],"metadata":{"id":"vtWgSLY0dpQQ","executionInfo":{"status":"ok","timestamp":1668204830276,"user_tz":480,"elapsed":8177,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"7hQB4Ifx8M1k","executionInfo":{"status":"ok","timestamp":1668204942201,"user_tz":480,"elapsed":111931,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}},"outputId":"27c711fe-38ed-4174-ed41-bdca7fdc785d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.10.1\n","  Downloading torch-1.10.1-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n","\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.2 MB/s eta 0:00:40tcmalloc: large alloc 1147494400 bytes == 0x6577c000 @  0x7fe90ef23615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n","\u001b[K     |████████████████████████████████| 881.9 MB 16 kB/s \n","\u001b[?25hCollecting torchvision==0.11.2\n","  Downloading torchvision-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n","\u001b[K     |████████████████████████████████| 23.3 MB 82.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.1) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.2) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.2) (7.1.2)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.1+cu113\n","    Uninstalling torchvision-0.13.1+cu113:\n","      Successfully uninstalled torchvision-0.13.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\u001b[0m\n","Successfully installed torch-1.10.1 torchvision-0.11.2\n"]}],"source":["pip install torch==1.10.1 torchvision==0.11.2"]},{"cell_type":"markdown","metadata":{"id":"hXn_-PZqTWB4"},"source":["### Download the MegaDetector model files\n","\n","We'll download both MegaDetector v5a and v5b.  See the [release notes](https://github.com/microsoft/CameraTraps/releases/tag/v5.0) for information about the differences between the two models."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"s5uwmpmaTZMX","executionInfo":{"status":"ok","timestamp":1668204974496,"user_tz":480,"elapsed":32301,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}},"outputId":"415a2ebb-f449-4e90-be60-c5405375e687","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-11-11 22:15:41--  https://github.com/microsoft/CameraTraps/releases/download/v5.0/md_v5a.0.0.pt\n","Resolving github.com (github.com)... 140.82.121.3\n","Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/152634113/d9cc1539-b05c-46b2-b677-26aa5fe8e392?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221111%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221111T221541Z&X-Amz-Expires=300&X-Amz-Signature=b2f657236b87d898396fca76fd69afad4eccbc4b948c0a7c6e60580560caaba1&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=152634113&response-content-disposition=attachment%3B%20filename%3Dmd_v5a.0.0.pt&response-content-type=application%2Foctet-stream [following]\n","--2022-11-11 22:15:41--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/152634113/d9cc1539-b05c-46b2-b677-26aa5fe8e392?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221111%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221111T221541Z&X-Amz-Expires=300&X-Amz-Signature=b2f657236b87d898396fca76fd69afad4eccbc4b948c0a7c6e60580560caaba1&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=152634113&response-content-disposition=attachment%3B%20filename%3Dmd_v5a.0.0.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 280766885 (268M) [application/octet-stream]\n","Saving to: ‘/content/md_v5a.0.0.pt’\n","\n","/content/md_v5a.0.0 100%[===================>] 267.76M  14.0MB/s    in 15s     \n","\n","2022-11-11 22:15:56 (18.0 MB/s) - ‘/content/md_v5a.0.0.pt’ saved [280766885/280766885]\n","\n","--2022-11-11 22:15:56--  https://github.com/microsoft/CameraTraps/releases/download/v5.0/md_v5b.0.0.pt\n","Resolving github.com (github.com)... 140.82.121.3\n","Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/152634113/20a12a41-6bc2-4c17-aa36-42dde50c2a2b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221111%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221111T221557Z&X-Amz-Expires=300&X-Amz-Signature=1d68a82fa587eb628f83b3ea607137e4a0f9cc334e68550658a28fa46b07edc7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=152634113&response-content-disposition=attachment%3B%20filename%3Dmd_v5b.0.0.pt&response-content-type=application%2Foctet-stream [following]\n","--2022-11-11 22:15:57--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/152634113/20a12a41-6bc2-4c17-aa36-42dde50c2a2b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221111%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221111T221557Z&X-Amz-Expires=300&X-Amz-Signature=1d68a82fa587eb628f83b3ea607137e4a0f9cc334e68550658a28fa46b07edc7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=152634113&response-content-disposition=attachment%3B%20filename%3Dmd_v5b.0.0.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 280766885 (268M) [application/octet-stream]\n","Saving to: ‘/content/md_v5b.0.0.pt’\n","\n","/content/md_v5b.0.0  47%[========>           ] 127.76M  6.32MB/s    eta 17s    ^C\n"]}],"source":["!wget -O /content/md_v5a.0.0.pt https://github.com/microsoft/CameraTraps/releases/download/v5.0/md_v5a.0.0.pt\n","!wget -O /content/md_v5b.0.0.pt https://github.com/microsoft/CameraTraps/releases/download/v5.0/md_v5b.0.0.pt "]},{"cell_type":"markdown","metadata":{"id":"nmJ6lQX8S4im"},"source":["### Clone the required git repos\n","This will copy the latest version of the Microsoft AI for Earth \"utilities\" and \"CameraTraps\" repositories from GitHub, as well as the YOLOv5 repo, all of which are required to run MegaDetector."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"7qhltAaRSe1W","executionInfo":{"status":"ok","timestamp":1668204985639,"user_tz":480,"elapsed":11152,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}},"outputId":"a4b59da4-1723-4064-f6a5-dccc719a0eca","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'CameraTraps'...\n","remote: Enumerating objects: 14201, done.\u001b[K\n","remote: Counting objects: 100% (1123/1123), done.\u001b[K\n","remote: Compressing objects: 100% (454/454), done.\u001b[K\n","remote: Total 14201 (delta 720), reused 1035 (delta 668), pack-reused 13078\u001b[K\n","Receiving objects: 100% (14201/14201), 169.55 MiB | 24.64 MiB/s, done.\n","Resolving deltas: 100% (8541/8541), done.\n","Cloning into 'ai4eutils'...\n","remote: Enumerating objects: 761, done.\u001b[K\n","remote: Counting objects: 100% (67/67), done.\u001b[K\n","remote: Compressing objects: 100% (36/36), done.\u001b[K\n","remote: Total 761 (delta 41), reused 36 (delta 31), pack-reused 694\u001b[K\n","Receiving objects: 100% (761/761), 2.58 MiB | 19.14 MiB/s, done.\n","Resolving deltas: 100% (456/456), done.\n","Cloning into 'yolov5'...\n","remote: Enumerating objects: 14799, done.\u001b[K\n","remote: Counting objects: 100% (130/130), done.\u001b[K\n","remote: Compressing objects: 100% (83/83), done.\u001b[K\n","remote: Total 14799 (delta 75), reused 89 (delta 47), pack-reused 14669\u001b[K\n","Receiving objects: 100% (14799/14799), 13.60 MiB | 23.98 MiB/s, done.\n","Resolving deltas: 100% (10212/10212), done.\n","Note: checking out 'c23a441c9df7ca9b1f275e8c8719c949269160d1'.\n","\n","You are in 'detached HEAD' state. You can look around, make experimental\n","changes and commit them, and you can discard any commits you make in this\n","state without impacting any branches by performing another checkout.\n","\n","If you want to create a new branch to retain commits you create, you may\n","do so (now or later) by using -b with the checkout command again. Example:\n","\n","  git checkout -b <new-branch-name>\n","\n","HEAD is now at c23a441 Improved `dataset_stats()` YAML checks (#8125)\n"]}],"source":["!git clone https://github.com/microsoft/CameraTraps\n","!git clone https://github.com/microsoft/ai4eutils\n","!git clone https://github.com/ultralytics/yolov5/\n","!cd yolov5 && git checkout c23a441c9df7ca9b1f275e8c8719c949269160d1"]},{"cell_type":"markdown","metadata":{"id":"2pzfM5Y-iby1"},"source":["### Set `PYTHONPATH` to include `CameraTraps`, `ai4eutils`, and `yolov5`\n","\n","Add cloned git folders to the `PYTHONPATH` environment variable so that we can import their modules from any working directory.\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"d8vanlgAOlEj","executionInfo":{"status":"ok","timestamp":1668204985639,"user_tz":480,"elapsed":13,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}}},"outputs":[],"source":["import os\n","os.environ['PYTHONPATH'] += \":/content/ai4eutils\"\n","os.environ['PYTHONPATH'] += \":/content/CameraTraps\"\n","os.environ['PYTHONPATH'] += \":/content/yolov5\""]},{"cell_type":"markdown","metadata":{"id":"JyjEgkCsOsak"},"source":["## Mount Google Drive in Colab\n","You can mount your Google Drive if you have your sample images there, or if want to save the results to your Google Drive.  \n","\n","Once you run the cell below, you will be prompted to authorize Colab to access your Google Drive.  Your Google Drive folders will then be mounted under `/content/drive` and can be viewed and navigated in the Files pane in Colab.\n","\n","The method is described in [this Colab code snippet](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveA)."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"XYsrTTR7eF0r","executionInfo":{"status":"ok","timestamp":1668205009230,"user_tz":480,"elapsed":23603,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}},"outputId":"dbf2122f-bf09-4bc9-d847-ee58005da23c","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"yM3Dl0Bfe0EM"},"source":["## Download sample images (I didn't use this step)\n","\n","We install Microsoft's [azcopy](https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10) utility, which we then use to download a few camera trap images from the [Snapshot Serengeti](http://lila.science/datasets/snapshot-serengeti) dataset hosted on [lila.science](http://lila.science).  If you are using your own data, you can skip this step."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"gAkYScsLe0EM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668205012992,"user_tz":480,"elapsed":3766,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}},"outputId":"a9a2a881-423b-481e-e0ef-8774a65f91f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Process is terminated.\n"]}],"source":["%%bash\n","\n","# Download azcopy\n","wget -q -O azcopy_linux.tar.gz https://aka.ms/downloadazcopy-v10-linux\n","tar -xvzf azcopy_linux.tar.gz --wildcards */azcopy --strip 1\n","rm azcopy_linux.tar.gz\n","chmod u+x azcopy\n","\n","# Copy a few Snapshot Serengeti images to a local directory\n","DATASET_URL=\"https://lilablobssc.blob.core.windows.net/snapshotserengeti-unzipped/\"\n","SAMPLE_DIR=\"S1/D05/D05_R4\"\n","LOCAL_DIR=\"/content/snapshotserengeti\"\n","\n","./azcopy cp \"${DATASET_URL}${SAMPLE_DIR}\" \"${LOCAL_DIR}\" --recursive"]},{"cell_type":"code","source":[],"metadata":{"id":"14nNbhptZqsl","executionInfo":{"status":"ok","timestamp":1668205012992,"user_tz":480,"elapsed":7,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lkugt7r3uUEr"},"source":["## MegaDetector batch processing\n","\n","This step executes the Python script `run_detector_batch.py` from the CameraTraps repo. It has three mandatory arguments and one optional:\n","\n","1. Path to the MegaDetector model file\n","2. A folder containing images.  This notebook points to the folder where we just put our Snapshot Serengeti images; if your images were already on Google Drive, replace `[Image_Folder]` with your folder name.\n","3. The output JSON file location and name."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"pSIH-k0nfi73","executionInfo":{"status":"ok","timestamp":1668205093894,"user_tz":480,"elapsed":219,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}}},"outputs":[],"source":["images_dir = '/content/drive/Shared with me/UncroppedImages/bobcat'\n","\n","# Choose a location for the output JSON file\n","output_file_path = '/content/drive/My Drive/bobcat-megadetector-output.json'"]},{"cell_type":"markdown","metadata":{"id":"Bsvuux-yhpLw"},"source":["Here we pass the Python variable value `output_file_path` you specified above to the bash commands below using `$` (double quoting as there are spaces in this path), to run the script. This is so that we can refer to the output file path later for visualization."]},{"cell_type":"markdown","metadata":{"id":"3YZs9wT1sAgV"},"source":["# Run the detection script\n","\n","There are actually two variants of MegaDetector v5, called \"v5a\" and \"v5b\".  By default this notebook runs MDv5a; change \"md_v5a.0.0.pt\" to \"md_v5b.0.0.pt\" to run MDv5b instead.\n","\n","Both run at the same speed; if you are in a Colab session with a GPU accelerator, you should be able to process around four images per second."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"3AOKfviGuTNg","executionInfo":{"status":"ok","timestamp":1668205097328,"user_tz":480,"elapsed":863,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}},"outputId":"f10ea731-98e7-4bd1-93f7-943b34f3f052","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/content/CameraTraps/detection/run_detector_batch.py\", line 737, in <module>\n","    main()\n","  File \"/content/CameraTraps/detection/run_detector_batch.py\", line 624, in main\n","    assert os.path.isdir(args.image_file), 'Could not find folder {}, must supply a folder when --output_relative_filenames is set'.format(args.image_file)\n","AssertionError: Could not find folder /content/drive/Shared with me/UncroppedImages/bobcat, must supply a folder when --output_relative_filenames is set\n"]}],"source":["!python /content/CameraTraps/detection/run_detector_batch.py md_v5a.0.0.pt \"$images_dir\" \"$output_file_path\" --recursive --output_relative_filenames --quiet"]},{"cell_type":"markdown","metadata":{"id":"-tHu5WUGDpcd"},"source":["## Visualize batch processing script outputs\n","\n","Here we use the `visualize_detector_output.py` in the `visualization` folder of the Camera Traps repo to see the output of the MegaDetector visualized on our images. It will save images annotated with the results (original images will *not* be modified) to the folder you specify here.\n","\n","The scripts take in a number of optional parameters to control output image size and how many are sampled (if you've processed a lot of images but only want to visualize the results on a few) - take a look at the `main()` function in the script to see what other parameters are available."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"en3TbCftkWDE","executionInfo":{"status":"ok","timestamp":1668205015077,"user_tz":480,"elapsed":835,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}},"outputId":"f6fb602f-a0aa-455b-dae0-aabae9e05664","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/content/CameraTraps/visualization/visualize_detector_output.py\", line 232, in <module>\n","    main()\n","  File \"/content/CameraTraps/visualization/visualize_detector_output.py\", line 228, in main\n","    render_detections_only=args.detections_only)\n","  File \"/content/CameraTraps/visualization/visualize_detector_output.py\", line 65, in visualize_detector_output\n","    f'Detector output file does not exist at {detector_output_path}.')\n","AssertionError: Detector output file does not exist at /content/drive/Shared with me/UncroppedImages/bobcat.\n"]}],"source":["# Render bounding boxes on our images\n","visualization_dir = '/content/visualized_images'\n","!python /content/CameraTraps/visualization/visualize_detector_output.py \"$output_file_path\" \"$visualization_dir\" --confidence 0.2 --images_dir \"$images_dir\""]},{"cell_type":"code","execution_count":12,"metadata":{"id":"AglNEK0goyjA","executionInfo":{"status":"error","timestamp":1668205015399,"user_tz":480,"elapsed":324,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}},"outputId":"6de41209-cda2-4948-9054-a1da7207a8aa","colab":{"base_uri":"https://localhost:8080/","height":235}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-144c58f19cd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mviz_file_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisualization_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviz_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisualization_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mviz_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/visualized_images'"]}],"source":["# Show the images with bounding boxes in Colab\n","import os\n","from PIL import Image\n","\n","for viz_file_name in os.listdir(visualization_dir):\n","  print(viz_file_name)\n","  im = Image.open(os.path.join(visualization_dir, viz_file_name))\n","  display(im)"]},{"cell_type":"markdown","source":["# Crop Images\n","\n"],"metadata":{"id":"UBx7vLPdaUky"}},{"cell_type":"code","source":[],"metadata":{"id":"sZWwJIaMnXgy","executionInfo":{"status":"aborted","timestamp":1668205015400,"user_tz":480,"elapsed":10,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"N9x4yrQNnXcj","executionInfo":{"status":"aborted","timestamp":1668205015400,"user_tz":480,"elapsed":10,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["detections_path = '/content/drive/My Drive/CS230/toy-megadetector-results.json'\n","crops_dir = '/content/drive/My Drive/CS230/'\n","images_dir = '/content/drive/My Drive/CS230/ToyImages'\n","log_dir = '/content/drive/My Drive/CS230/'"],"metadata":{"id":"G9aYbYDYcAVm","executionInfo":{"status":"aborted","timestamp":1668205015401,"user_tz":480,"elapsed":10,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/CameraTraps/classification/crop_detections.py \"$detections_path\"  \"$crops_dir\" \\\n","    --images-dir \"$images_dir\" \\\n","    --threshold 0.8 \\\n","    --save-full-images --square-crops \\\n","    --threads 50 \\\n","    --logdir \"$log_dir\""],"metadata":{"id":"XQeHsfSBaaQK","executionInfo":{"status":"aborted","timestamp":1668205015401,"user_tz":480,"elapsed":10,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Run classifier"],"metadata":{"id":"skAoe5l6eV-O"}},{"cell_type":"code","source":["output_path = '/content/drive/My Drive/CS230/classifier_output.csv'\n","detections_path = '/content/drive/My Drive/CS230/toy-megadetector-results.json'\n","crops_dir = '/content/drive/My Drive/CS230/'\n","images_dir = '/content/drive/My Drive/CS230/ToyImages'\n","log_dir = '/content/drive/My Drive/CS230/'"],"metadata":{"id":"oZ5MsH3hemAB","executionInfo":{"status":"aborted","timestamp":1668205015401,"user_tz":480,"elapsed":10,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/CameraTraps/classification/run_classifier.py \\\n","    /content/CameraTraps/classifier/efficientnet/v0.1_efficientnet-b3_compiled.pt \\\n","    \"$crops_dir\" \\\n","    \"$output_path\" \\\n","    --detections-json \"$detections_path\" \\\n","    --image-size 300 --batch-size 64 --num-workers 8"],"metadata":{"id":"Yul04wbaeZQN","executionInfo":{"status":"aborted","timestamp":1668205015402,"user_tz":480,"elapsed":11,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ycce0Oi_e0EQ"},"source":["# Next steps\n","\n","Now that you have run MegaDetector on a few images, here are some pointers to help you take advantage of MegaDetector to label your survey images more quickly.\n","\n","### Ways to use the output .json in a camera trap image processing workflow \n","\n","#### 1. Timelapse\n","\n","[Timelapse](http://saul.cpsc.ucalgary.ca/timelapse/pmwiki.php?n=Main.HomePage) is an open-source tool for annotating camera trap images. We have worked with the Timelapse developer to integrate MegaDetector results into Timelapse, so a user can:\n","\n","- Select or sort images based on whether they contain animal or people or vehicles.\n","- View bounding boxes during additional manual annotation steps\n","\n","See the [Timelapse Image Recognition Guide](https://saul.cpsc.ucalgary.ca/timelapse/uploads/Guides/TimelapseImageRecognitionGuide.pdf) for more information.\n","\n","![Screenshot showing the Timelapse application with MegaDetector output, shown as a bounding box around the detected animal](https://github.com/microsoft/CameraTraps/blob/main/api/batch_processing/integration/images/tl_boxes.jpg?raw=1)\n","\n","\n","#### 2. Separating images into folders that contain animals/people/vehicles/nothing\n","\n","Some MegaDetector users do image review without Timelapse, by moving the images to separate folders containing animals/people/vehicles/nothing according to MegaDetector output. You can use the script [separate_detections_into_folders.py](https://github.com/microsoft/CameraTraps/blob/master/api/batch_processing/postprocessing/separate_detections_into_folders.py) for this.\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"Zev9fCdnwXhr","executionInfo":{"status":"aborted","timestamp":1668205015402,"user_tz":480,"elapsed":11,"user":{"displayName":"Maya Regina Frohna","userId":"07118435221959034050"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"15K0dSIaUMnJJCMU86hIXvMAqcCfO41tw","timestamp":1668201749356},{"file_id":"https://github.com/microsoft/CameraTraps/blob/master/detection/megadetector_colab.ipynb","timestamp":1668038778340}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}